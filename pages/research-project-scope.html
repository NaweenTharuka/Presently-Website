<head>
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta http-equiv="content-type" content="text/html; charset=utf-8" />
    <meta name="author" content="INSPIRO" />
    <meta name="description" content="Themeforest Template Polo">

    <title>Presently</title>

    <link href="../css/plugins.css" rel="stylesheet">
    <link href="../css/style.css" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.1.1/css/all.min.css" integrity="sha512-KfkfwYDsLkIlwQp6LFnl8zNdLGxu9YAA1QvwINks4PhcElQSvqcyVLLD9aMhXd13uQjoXtEKNosOWaZqXgel0g==" crossorigin="anonymous" referrerpolicy="no-referrer" />
</head>

<body class="background-black">

    <div class="body-inner">

        <header id="header" class="header-mini dark">
            <div class="header-inner">
                <div class="container">

                    <div id="logo"><img src="/images/logo.png" style="width: 300px;"></div>

                    <div id="mainMenu-trigger"> <a class="lines-button x"><span class="lines"></span></a> </div>

                    <div id="mainMenu">
                        <div class="container">
                            <nav>
                                <ul>
                                    <li><a href="../home.html">Home</a></li>
                                    <li class="dropdown"><a href="#">Project</a>
                                        <ul class="dropdown-menu">
                                            <li><a href="research-project-scope.html">Research Project Scope</a>
                                            </li>
                                            <li><a href="research-project-milestones.html">Research Project Milestones</a>
                                            </li>
                                        </ul>
                                    </li>
                                    <li><a href="documents.html">Documents</a></li>
                                    <li><a href="presentations.html">Presentations</a></li>
                                    <li><a href="aboutus.html">About us</a></li>
                                    <li><a href="contactus.html">Contact us</a></li>
                                </ul>
                            </nav>
                        </div>
                    </div>

                </div>
            </div>
        </header>

        <section id="page-content">
            <div class="container">
                <div>
                    <div class="page-title m-b-20">
                        <h3>Litrature survey</h3>
                    </div>
                    <div class="row">
                        <div class="content col-lg-9">
                            <p><span class="dropcap"> 2 </span>020, H. Zeng et al., [2] in the research paper introduces “EmoCo” system, 
                                which is an interactive visual analytics system for monitoring emotion coherence in presentation videos 
                                across several behavioral methodologies. (Video, Sentence, Word levels, and the Way of emotions categorization 
                                varies). In here it explains the combination of all possible emotion categories that are taken for the 
                                calculations of the final emotion coherence. Furthermore, the emotions such as anger, happiness, neutral 
                                and sadness has been used here as they are the most common major emotion [2] categories. This method- ology 
                                supports visual research of videos by combining well- established visualization techniques with innovative 
                                designs. A detail view and a word view, respectively, allow for deep research and comparison at the sentences 
                                and word levels. Using a feedforward learning model, an instructor’s facial expression recognition approach in 
                                a classroom is introduced in research paper [3]. As for the solution discovered in the paper [3], through the 
                                effective high-level feature extraction, the face is first detected from the collected lecture videos and 
                                important frames are selected, removing all unnecessary frames. Then, using several convolution neural networks 
                                and parameter tuning, deep features are extracted and supplied to a classifier. A regularized extreme learning 
                                machine (RELM) classifier is used to classify the instructor’s five various expressions (Amusement, Awe, Confident, 
                                Disappointment, Neutral) in the classroom. Experiments are carried out in classroom using a newly built instructor’s 
                                facial expression dataset as well as three benchmark face datasets. Meanwhile, in the proposed system “Presently” 
                                implement not only the common methods of extracting emotions but also the other more advanced methodologies with 
                                the more emotion categories extended with analysis of hand gestures. As it is tiresome and time-consuming to 
                                manually view and study presentation videos, the “Presently” is novel approach to be used.
                                <br />
                                <br />This paper presents [4] an emotional speaker recognition system trained on an emotional voice database using 
                                machine and deep learning techniques with timing, frequency, and spectral properties. The features are normalized 
                                using the z- score feature [4] normalization once they are extracted from the speech database. Furthermore, 
                                by utilizing training data to develop models, and testing data to evaluate models by making predictions and 
                                comparing them to true labels. This research described a speaker recognition system that used an emotional 
                                database of eight emotions, rather than a standard database. A. Kamat et al., 2017 [5] introduce the three 
                                prosodic characteristics at the word and syllable levels to modify the prosody of a neutral carrier sentence 
                                to generate narrow- focus emphasis on specific target words. The availability of effective prosodic features 
                                in achieving the target word stress referred to as prosodic-differential in this[5], is assessed using ABX 
                                listening tests [5] that yield both categorical and graded responses to determine how effective a particular 
                                prosodic feature or specific combinations are in achieving the narrow- focus word-stress. Emotions recognition 
                                utilizing the audio file from the uploaded video presentation and prosody detection are two newer features of 
                                ”Presently” that will help presenters evaluate themselves more effectively. Prosody error detection is significant 
                                during a presentation since it allows the audience to absorb the content clearly and grasp it better.
                                <br />
                                <br />This work [6] examines spoken English pronunciation input speech signals, digitizes them, and converts them 
                                to digital signals. An automatic correction system of spoken English pronunciation errors based on phonemes 
                                is meant to improve the accuracy of automatic correction of spoken English pronunciation flaws. In the majority 
                                of end-to-end speech recognition systems models [7], speech is a sequence of characters or sub-words. Existing 
                                practices for sub-word extraction only examine character sequence frequencies that could result in poor sub-word 
                                separation and inaccurate speech recognition output. The above system consists of pronunciation-assisted sub-word 
                                modeling (PASM), a sub-word extraction method that makes use of a word’s pronunciation features. Deshpande et al., 
                                2020[8]present a web-based framework for evaluating, understanding, and improving public speaking skills to 
                                as- sist individuals in delivering better speeches, presentations, or improving business interactions. This method 
                                is used to investigate and visualize many figures of language, such as machine-generated transcriptions and vocal 
                                parts of users’ recorded voices. This allowed the users to self-evaluate the speech by using the speech 
                                characteristics and graphs of the speech. “Presently” would help the presenters to improve the pronunciation 
                                faults that occur while presenting using various NLP techniques without using the most basic and common 
                                methodologies. Also, Presently will provide the presenter with incorrect grammar error sentences that occurs 
                                during the speech. Even though pronunciation and vocabulary are common in NLP, the approaches that have been 
                                used in the Presently will be unique and more accurate when it comes to these features.
                                <br />
                                <br />A variety of strategies and procedures for editing and improving presentation slides have been proposed so far. 
                                The majority of them concentrate on composing and displaying, for example, page management. According to Yusra 
                                Khalid Bhatti et al., 2021[9], a ranking system was introduced, for presentation slides to help users to improve 
                                the visibility of the presentations. This approach serves as a self-checking tool for presenting novices, 
                                reducing seemingly unreadable or hidden items that are frequently neglected by users with little presentation 
                                experience. The suggested approach is useful for an instructor teaching student how to produce presentations 
                                because the system may perform a basic accessibility check prior to the actual evaluation of the work. 
                                The paper [10] presents a methodology for coloring the characteristics of slides in the presentation slides. 
                                For this, Term-Frequency (TF), Inverse Document Frequency (IDF), and Words in the Conclusion slide and textbox (WCT) are used. 
                                A web-based system was introduced in the paper [10] for identifying the source URLs of images featured in 
                                presentations. This system extracts all of the images present in the presentation slides uploaded to the 
                                system and displays the numerous source URL candidates for the images likely to have appeared on the Internet. 
                                “Presently” evaluates to assist presenters in improving their presentations by detecting the accuracy and 
                                attractiveness using color themes, contrast, sharpness, etc. This helps to design a more attractive and more 
                                accurate set of slides for the final presentation.</p>
                            <hr class="space">
                        </div>
                    </div>
                </div>
                <div>
                    <div class="page-title m-b-20">
                        <h3>Research Gap</h3>
                    </div>
                    <div class="row">
                        <div class="content col-lg-9">
                            <p><span class="dropcap"> A </span>ccording to the research papers we have read in the past few days, there are not many
                                research papers that have been conducted in the Presentation analysis area. There is no proper research paper to 
                                evaluate presenter’s presentation skills. There is no proper research paper to evaluate presenter’s emotions and body 
                                language using video analysis at the same time. Many research articles and systems have been developed to
                                detect users’ emotions, but an expert system to detect and recognize emotions and body language while presenting a 
                                presentation has yet to be developed. Also there is not any research that have been conducted to detect presentation
                                quality using various parameters. When creating an application to predict presentation skills there should be a way to detect
                                emotions and also prosody levels. But the exciting systems predict only limited types of emotions while speaking.
                                <br />
                                <br />
                                As a conclusion, we proposed the “Presently” system, which will assess a speaker's presentation skills based on several 
                                factors such as pronunciation, vocabulary, emotions, facial expressions, intonation, prosody, and slide quality.
                            
                            </p>
                            <hr class="space">
                        </div>
                    </div>
                </div>
                <div>
                    <div class="page-title m-b-20">
                        <h3>Research Problem</h3>
                    </div>
                    <div class="row">
                        <div class="content col-lg-9">
                            <p><span class="dropcap"> N </span>on-Professional speakers like academic students face many 
                                difficulties while preparing for a speech or a presentation. People are concerned about speaking 
                                English since they frequently make grammatical and vocabulary flaws. This is very common while 
                                performing a presentation. Not practicing enough, become nervous, avoiding eye contact, failing to 
                                engage emotionally, presentation slides are not attractive are some of the main difficulties people had 
                                to face when doing a presentation. Therefore, practice in advance to the presentation helps to stable
                                the emotions while doing the presentation. Getting feedback before doing the presentation will help 
                                the speaker to improve their presentation skills. Most speakers use manual methods to get feedback. 
                                There is no proper method to self-evaluate presentation performance. As per the survey we conducted
                                many university students have not used any existing systems to self-evaluate their presentation 
                                skills before the actual presentation</p>
                            <hr class="space">
                        </div>
                    </div>
                </div>
                <div>
                    <div class="page-title m-b-20">
                        <h3>Research Objective</h3>
                    </div>
                    <div class="row">
                        <div class="content col-lg-9">
                            <p><span class="dropcap"> T </span>he main objective of the implementation of “Presently” is to 
                                work as a personal trainer app to self-train and improve presentation skills. This Mobile 
                                Responsive Web Application would help presenters to prepare beforehand for the presentations 
                                to deliver a successful speech to the audience. In this research, we focus on analyzing the audio, 
                                video, and slides of the presentation uploaded by the speakers. Preparing for a presentation has 
                                been shown to be essential for improving emotional control, intonation and prosody, pronunciation 
                                and vocabulary, as well as the quality of the presentation slides. As a result, practicing has 
                                become one of the most critical parts of giving a good presentation. The “Presently” will 
                                assist in practicing the presentation beforehand by identifying the presenters’ emotions, 
                                body language, tonality, prosody, pronunciations and vocabulary, and presentation slides quality. 
                                Overall, the system will give a rating and feedback to the presenter about the performance, so 
                                that the presenters’ can improve their presentation skills.</p>
                            <hr class="space">
                        </div>
                    </div>
                </div>
                <div>
                    <div class="page-title m-b-20">
                        <h3>Methodology</h3>
                    </div>
                    <div class="row">
                        <div class="content col-lg-9">
                            <p><span class="dropcap"> P </span>racticing the presentation beforehand has become one of the 
                                most crucial parts of giving a good presentation. Whenever a video clip of the presentation 
                                is uploaded by the presenter, the proposed system will extract the audio clip and analyzes it 
                                independently for any inaccurate pronunciation and vocabulary errors and will detect the emotional 
                                imbalances of the presenters’ speech. The proposed system also has the functionality to detect 
                                emotions and hand gestures from the video file uploaded by the presenters. Slide quality checking 
                                is also another essential functionality provided by the ”Presently” to guide the presenters throughout 
                                the process of user-friendly presentation slide creation. The necessity of this whole process is to 
                                improve the presentation skills of the presenters to carry out a successful presentation at the end of the day.</p>
                            <hr class="space">
                        </div>
                    </div>
                </div>
                <div>
                    <div class="page-title m-b-20">
                        <h3>Technologies</h3>
                    </div>
                    <div class="row">
                        <div class="content col-lg-9 row">
                            <div class="col-lg-3">
                                <ul class="list-icon list-icon-colored">
                                    <li><i class="fa fa-paper-plane"></i>Python</li>
                                    <li><i class="fa fa-paper-plane"></i>Python Django & Bootstrap</li>
                                    <li><i class="fa fa-paper-plane"></i>Pycharm Anaconda Plugins</li>
                                    <li><i class="fa fa-paper-plane"></i>Praat</li>
                                </ul>
                            </div>
                            <div class="col-lg-3">
                                <ul class="list-icon list-icon-colored">
                                    <li><i class="fa fa-paper-plane"></i>Mediapipe</li>
                                    <li><i class="fa fa-paper-plane"></i>Convolutional Neural Network(CNN)</li>
                                    <li><i class="fa fa-paper-plane"></i>Tensorflow</li>
                                    <li><i class="fa fa-paper-plane"></i>Jupyter Notebook</li>
                                </ul>
                            </div>
                            <hr class="space">
                        </div>
                    </div>
                </div>
            </div>
        </section>                            


        <footer id="footer">
            <div class="copyright-content">
                <div class="container">
                    <div class="copyright-text text-center">&copy; 2022 Team Presently.
                        All Rights Reserved.</div>
                </div>
            </div>
        </footer>

    </div>


    <a id="scrollTop"><i class="icon-chevron-up"></i><i class="icon-chevron-up"></i></a>

    <script src="../js/jquery.js"></script>
    <script src="../js/plugins.js"></script>

    <script src="../js/functions.js"></script>
</body>

</html>